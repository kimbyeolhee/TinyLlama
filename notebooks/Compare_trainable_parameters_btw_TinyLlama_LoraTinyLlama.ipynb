{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:11:30.008105Z",
     "start_time": "2023-09-21T02:11:26.774217Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:38:50.293163Z",
     "start_time": "2023-09-21T02:38:50.290777Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:11:30.013132Z",
     "start_time": "2023-09-21T02:11:30.011100Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:11:30.026134Z",
     "start_time": "2023-09-21T02:11:30.014223Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model, use_4bit=False):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    if use_4bit:\n",
    "        trainable_params /= 2\n",
    "    print(\n",
    "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    return bnb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:35:03.483909Z",
     "start_time": "2023-09-21T02:35:03.479797Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T01:52:12.408692Z",
     "start_time": "2023-09-21T01:52:12.406608Z"
    }
   },
   "source": [
    "# Load TinyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:31:38.233713Z",
     "start_time": "2023-09-21T05:31:38.231558Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"PY007/TinyLlama-1.1B-Chat-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:31:39.857580Z",
     "start_time": "2023-09-21T05:31:38.457465Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tiny_llama = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:15:54.364236Z",
     "start_time": "2023-09-21T02:15:54.360081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all params: 1,100,060,672 || trainable params: 1,100,060,672 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(tiny_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:31:51.742716Z",
     "start_time": "2023-09-21T05:31:51.736991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 1100060672 1.0\n"
     ]
    }
   ],
   "source": [
    "dtypes = {}\n",
    "for _, p in tiny_llama.named_parameters():\n",
    "    dtype = p.dtype\n",
    "    if dtype not in dtypes: dtypes[dtype] = 0\n",
    "    dtypes[dtype] += p.numel()\n",
    "total = 0\n",
    "for k, v in dtypes.items(): total+= v\n",
    "for k, v in dtypes.items():\n",
    "    print(k, v, v/total)\n",
    "\n",
    "do_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA TinyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:04.091180Z",
     "start_time": "2023-09-21T05:32:04.089002Z"
    }
   },
   "outputs": [],
   "source": [
    "modules = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:04.588177Z",
     "start_time": "2023-09-21T05:32:04.585595Z"
    }
   },
   "outputs": [],
   "source": [
    "# peft_config\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:08.105490Z",
     "start_time": "2023-09-21T05:32:07.272370Z"
    }
   },
   "outputs": [],
   "source": [
    "tiny_llama_lora = get_peft_model(tiny_llama, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T02:39:41.171316Z",
     "start_time": "2023-09-21T02:39:41.166219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,313,472 || trainable%: 0.20437017756052608\n"
     ]
    }
   ],
   "source": [
    "tiny_llama_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:14.573795Z",
     "start_time": "2023-09-21T05:32:14.567533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 1102313472 1.0\n"
     ]
    }
   ],
   "source": [
    "dtypes = {}\n",
    "for _, p in tiny_llama_lora.named_parameters():\n",
    "    dtype = p.dtype\n",
    "    if dtype not in dtypes: dtypes[dtype] = 0\n",
    "    dtypes[dtype] += p.numel()\n",
    "total = 0\n",
    "for k, v in dtypes.items(): total+= v\n",
    "for k, v in dtypes.items():\n",
    "    print(k, v, v/total)\n",
    "\n",
    "do_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bnb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:27.185530Z",
     "start_time": "2023-09-21T05:32:27.181978Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = create_bnb_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:28.937592Z",
     "start_time": "2023-09-21T05:32:27.454491Z"
    }
   },
   "outputs": [],
   "source": [
    "tiny_llama = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map = \"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:28.951409Z",
     "start_time": "2023-09-21T05:32:28.949477Z"
    }
   },
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(tiny_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:29.206245Z",
     "start_time": "2023-09-21T05:32:29.204153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_proj', 'gate_proj', 'q_proj', 'down_proj', 'k_proj', 'o_proj', 'up_proj']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:32.736918Z",
     "start_time": "2023-09-21T05:32:32.296058Z"
    }
   },
   "outputs": [],
   "source": [
    "tiny_llama_lora = get_peft_model(tiny_llama, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T04:11:06.738838Z",
     "start_time": "2023-09-21T04:11:06.734451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,313,472 || trainable%: 0.20437017756052608\n"
     ]
    }
   ],
   "source": [
    "tiny_llama_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T05:32:37.134664Z",
     "start_time": "2023-09-21T05:32:37.128144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16 131176448 0.2123038167685908\n",
      "torch.uint8 484442112 0.7840501168398548\n",
      "torch.float32 2252800 0.0036460663915543843\n"
     ]
    }
   ],
   "source": [
    "dtypes = {}\n",
    "for _, p in tiny_llama_lora.named_parameters():\n",
    "    dtype = p.dtype\n",
    "    if dtype not in dtypes: dtypes[dtype] = 0\n",
    "    dtypes[dtype] += p.numel()\n",
    "total = 0\n",
    "for k, v in dtypes.items(): total+= v\n",
    "for k, v in dtypes.items():\n",
    "    print(k, v, v/total)\n",
    "\n",
    "do_train = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
